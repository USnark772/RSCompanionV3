TODO: Pressing matters.
    - Implement camera activation/deactivation in app_model.py
        - grey out during experiment.
            - create/end experiment should handle this logic
    - Ensure app does not save experiment before devices finish saving. (Can we tell if a file is still opened?)
    - Make sure reading data from devices is done in threads so timestamps are not delayed.

TODO: At some point
    - Implement audio recording. (SimpleAudio, PyAudio, etc.)
        - Try to figure out which camera each mic belongs to and make that an mp4.
        - If mic is not attached to camera then save as audio file.
        - https://stackoverflow.com/questions/14140495/how-to-capture-a-video-and-audio-in-python-from-a-camera-or-webcam
    - Consider making properties out of our getter/setter methods.
        - https://www.python-course.eu/python3_properties.php
    - Check all modules for proper and complete logging usage.
    - Implement playback of experiment data.
        - Scanning through data example: DRT_7,_8,_9 clicks threshold x, scan through all by timestamp.
        - Reimplement saving as .rs files.
    - Figure out how to get app to work with non-ascii character languages. Issue seems to be with matplotlib.
        - Chinese
        - Japanese
        - Russian
    - Add more languages.
        - Top 10 most spoken languages would be nice.
    - Finish adding/translating languages for current string.py files.
    - Look over https://chrisyeh96.github.io/2017/08/08/definitive-guide-python-imports.html and make edits to imports.
    - Look at info_box.py empty QLabel items and consider a spacer item instead.
    - extract view from controller


TODO: Test this thing like crazy!
    - Look for if video is smooth on saved files even if it's not in the preview in the app.
    - Proper app usage tests.
    - Improper app usage tests.
